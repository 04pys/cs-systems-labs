# 2026-02-16

## What I did
- Lab05 false sharing 실험을 설계하고 `main.cpp`를 작성해 멀티스레드 환경에서 **packed vs padded**(cache line 분리 여부) 차이를 측정함  
- `std::thread` 기반으로 스레드를 생성하고, `SpinBarrier`로 시작/종료 구간을 정렬한 뒤 `rdtsc`로 사이클을 측정하는 벤치를 구성함  
- `pin_thread_to_cpu`(Linux에서의 thread affinity) 옵션을 추가해 pin=0/1 두 조건으로 실행하고 결과를 비교함  
- Colab 환경에서 `hw_threads = std::thread::hardware_concurrency()` 값이 2로 나오는 것을 확인하고, nthreads(1,2,4,8)에서 oversubscription이 섞일 수 있다는 점까지 고려해서 해석함  
- 결과 정리 과정에서 “왜 max(thread_cycles)를 쓰는지”, “왜 cycles_per_inc로 정규화하는지”, “thrash buffer / barrier / atomic이 필요한 이유”를 다시 점검하며 실험 의도를 명확히 함  

## Key results
- 고정 조건: iters_per_thread=50,000,000 / trials=11  
- **nthreads=1**
  - pin=0: packed 4.1608, padded 4.5250, ratio 0.9195
  - pin=1: packed 4.5115, padded 4.5181, ratio 0.9985
  - 단일 스레드에서는 false sharing 자체가 구조적으로 발생하지 않음(차이가 나도 원인이 다른 쪽일 가능성이 큼)
- **nthreads≥2에서는 packed가 padded보다 항상 느림(이번 데이터 기준)**
  - nthreads=2: ratio 3.4133(pin=0), 1.7479(pin=1)
  - nthreads=4: ratio 2.4021(pin=0), 2.7418(pin=1)
  - nthreads=8: ratio 1.9407(pin=0), 1.7411(pin=1)
- pinning은 크기(magnitude)를 바꾸지만 방향(direction)은 유지됨  
  - 모든 nthreads≥2에서 packed/padded > 1 유지  
  - 다만 pin의 효과가 단조적이지는 않음(2에서는 감소, 4에서는 증가, 8에서는 소폭 감소)

## Takeaways
- false sharing은 “같은 변수를 공유”하지 않아도 **같은 cache line을 공유**하면 발생할 수 있고, `alignas(64)` 같은 단순한 배치 변화로도 비용이 크게 갈릴 수 있음을 실험으로 확인함  
- `cycles_per_inc`를 쓰면 nthreads가 달라도(총 작업량이 달라도) **increment 1회당 비용**으로 비교가 가능해져 false sharing 페널티를 더 직접적으로 해석할 수 있음  
- 벤치에서 `max(cyc_per_thread)`를 쓰는 이유는, barrier로 구간을 맞춘 상황에서 “그 trial의 완료 시간”은 결국 가장 느린 스레드가 결정하기 때문이며, median을 취해 Colab의 스케줄링 노이즈/outlier 영향을 줄이는 방식이 합리적이라고 판단함  
- Colab에서 hw_threads=2라서 nthreads>2는 oversubscription이 섞이지만, 그 상태에서도 packed penalty가 지속적으로 관측되어 “측정 자체가 무의미해지는 건 아니다”는 점을 확인함  
- 다음 단계로는 (1) trial별 thread cycle 분포를 출력해서 tail/outlier를 더 직접 확인하고, (2) pinning이 실제로 적용되는지(affinity 확인)와 CPU 배치가 어떻게 되는지까지 같이 로그로 남기면 해석 신뢰도가 더 올라갈 것 같음  
