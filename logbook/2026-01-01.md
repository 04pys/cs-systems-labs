# 2026-01-01

## Done
- GitHub 레포 구조 초기 세팅 완료함(`logbook/`, `notes/`, `labs/`, `notebooks/`, `scripts/`)
- Colab에서 C++ 컴파일/실행 흐름 확립함(`g++`로 빌드 후 실행)
- lab01(cache_walk) 진행함: row-major vs col-major-like 접근 패턴 성능 차이 측정/분석함
- N=4로 인덱스 접근 순서를 확인해 접근 패턴을 직접 검증함
- N을 256~8192까지 스윕하며 row/col 성능 격차가 커지는 것을 데이터로 확인함

## Key takeaways
- CPU는 보통 캐시라인(예: 64B) 단위로 데이터를 가져오며, 연속 접근은 캐시라인 재사용률(공간 지역성)이 높아 유리함
- stride가 큰 접근은 캐시라인 낭비가 커지고 캐시 미스가 증가해 하위 계층(L2/L3/DRAM) 접근 비중이 커질 수 있음
- 큰 stride 접근은 페이지를 넓게 건드리며 TLB 엔트리 압박 → TLB miss 증가 가능성이 있고, prefetcher도 연속 패턴 대비 비효율적일 수 있음
- 결론적으로 SW의 데이터 레이아웃/루프 순서가 HW(캐시/TLB/prefetcher) 효율을 좌우함
- 위 사고방식은 이후 CUDA에서 coalescing/tiling(shared memory) 최적화로 자연스럽게 연결 가능함

## Output saved
- `labs/lab01_cache_walk/`에 코드/README/result 정리함
- 노트북(.ipynb)을 레포에 보관함(실험 과정/출력 보존 목적)

## Next
- `notes/cache-locality.md` 형태로 개념을 짧게 고정하고, 다음 lab 주제 선정함
- (선택) col-major-like를 tiling(블로킹)으로 개선하는 CPU 버전 실험을 lab02로 진행함
