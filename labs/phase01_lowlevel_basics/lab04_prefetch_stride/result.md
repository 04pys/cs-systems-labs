# lab04 prefetch 실험 결과 (main.cpp + test.cpp)

## 0) 실험 요약
- 목표: stride 접근 패턴에서 하드웨어 prefetcher만 쓸 때(base)와 `__builtin_prefetch`를 추가했을 때의 차이를 비교하고, stride별로 최적의 dist(몇 step ahead를 미리 가져올지)를 찾는 실험임  
- main.cpp: 실제로 `__builtin_prefetch(&a[i + dist*stride])`를 넣고 dist 후보들을 스윕해서, stride별 최적 dist를 직접 찾는 방식임  
- test.cpp: rdtsc 기반으로
  - 메모리 지연(대략적인 load latency)을 cycles로 추정하는 값 `L_lat_cyc`
  - 반복 1회당 계산/루프 오버헤드에 해당하는 값 `T_iter_cyc`
  를 구한 뒤, dist_pred를 계산해서 후보군을 좁히고(best_dist를 실험으로 선택) 그 결과를 출력하는 방식임  

> 참고: rdtsc, lfence, rdtscp 같은 측정 트릭은 notes로 따로 정리하였음.  
> C++에서 asm을 이용해 rdtsc, lfence 등을 이용해 cycle을 측정함.  

---

## 0-1) `__builtin_prefetch`가 실제로 하는 일
`__builtin_prefetch`는 함수처럼 보이지만, 실제 의미는 컴파일러 내장(intrinsic) 프리패치 힌트임. 특정 주소가 속한 캐시 라인을 미리 캐시에 올려서, 실제 load 시점의 지연을 줄일 수 있는지 관찰하는 도구로 쓰는 편이 자연스러움  

- 역할: `addr`가 속한 캐시 라인(보통 64B)을 미리 당겨오도록 CPU에 힌트를 주는 것임  
- 보장 없음: prefetch는 요청이 아니라 힌트라서, 하드웨어가 상황에 따라 무시하거나 지연시키는 것이 가능함  
  - 예: outstanding miss가 이미 많아 큐가 포화된 경우, 대역폭을 보수적으로 쓰는 경우, prefetcher 정책이 충돌하는 경우 등  
- 단위: 원소 단위가 아니라 캐시 라인 단위로 움직이는 효과임  
  - 따라서 `dist`를 튜닝한다는 것은 element 단위보다 cache line 단위로 얼마나 ahead를 보느냐와 강하게 연결됨  
- 부작용 가능: 너무 이른 prefetch는 캐시 오염, TLB pressure, 불필요 대역폭 사용으로 손해가 될 수 있음  

### `__builtin_prefetch(addr, rw, locality)` 인자 의미
- `addr`: 미리 당겨오고 싶은 주소임  
- `rw`: 0이면 read 목적, 1이면 write 목적 힌트임  
- `locality`: 0~3 힌트로, 대략 얼마나 오래 캐시에 두고 싶은지의 성향을 나타냄  
  - locality가 높을수록 재사용될 것이라는 가정이 강해지고, 낮을수록 캐시 오염을 줄이려는 방향(non-temporal에 가까운 성격)으로 해석될 수 있음  
- 중요한 점: `rw`, `locality` 모두 강제 옵션이 아니라 힌트라서, 실제 동작은 마이크로아키텍처 구현과 상황에 따라 달라질 수 있음  

---

## 1) main.cpp 실험 결과 (3회 중 median)
이번 입력에서 실험 로그 3개 중 2개가 동일하게 출력되었고, median은 동일 출력값이 그대로 선택됨  
따라서 아래 표의 값이 stride별 median 결과임  

### 1-1) stride별 base 대비 최적 dist 요약표
- best_dist는 이번 후보군 `{1,2,3,4,6,8,11,15,16,18,22,24,32,64}` 안에서 가장 빠른 dist임  
- 모든 pf가 base보다 느리면 best_dist를 none으로 표기함  

| stride | base_ms (median) | best_dist (median) | best_ms (median) | speedup |
|---:|---:|---:|---:|---:|
| 1 | 237.765 | none | 237.765 | 0.000% |
| 2 | 236.869 | 15 | 220.049 | 7.102% |
| 4 | 235.271 | 64 | 223.382 | 5.054% |
| 8 | 257.653 | 15 | 249.780 | 3.055% |
| 16 | 429.956 | 11 | 395.615 | 7.986% |
| 32 | 716.644 | 64 | 712.681 | 0.553% |
| 64 | 740.462 | none | 740.462 | 0.000% |
| 128 | 729.875 | none | 729.875 | 0.000% |
| 256 | 708.151 | none | 708.151 | 0.000% |
| 512 | 881.985 | 16 | 718.838 | 18.498% |
| 1024 | 970.170 | 18 | 792.255 | 18.338% |
| 2048 | 1036.760 | 24 | 810.968 | 21.779% |

### 1-2) main.cpp 결과를 stride별로 해석하기
아래는 위 표가 의미하는 바를, 각 stride 구간별로 나눠서 정리한 내용임  

#### (A) stride 1
- prefetch를 넣으면 전반적으로 느려짐  
- 이유 후보
  - 연속 접근에서는 하드웨어 prefetcher가 이미 매우 잘 따라오는 경우가 많아서, 소프트웨어 prefetch가 중복 요청이 되기 쉬움  
  - prefetch 자체가 명령어/프론트엔드/프리패치 큐에 부담을 줘서 오히려 손해가 날 수 있음  
  - 캐시 라인 재사용이 충분히 있는 패턴에서는 prefetch가 이득을 만들기 어렵고, 오히려 캐시 오염으로 손해가 날 수 있음  

#### (B) stride 2, 4, 8, 16
- dist를 적당히 잡으면 개선이 나타남(대략 3%~8% 정도)  
- 특징
  - stride가 커질수록 순수 연속 스트림이 아니라 여러 스트림처럼 보이거나, 프리패처가 덜 잘 맞는 순간이 생기기 쉬움  
  - 이 구간에서는 dist가 너무 작으면 아직 데이터가 도착하기 전이라 효과가 약하고, 너무 크면 불필요한 라인을 일찍 끌어와서 캐시 오염이 커질 수 있음  
- 이번 입력에서 관측된 best_dist
  - stride 2는 15, stride 8은 15, stride 16은 11 등으로, 작은 dist(1~4)보다 한참 큰 값이 이기는 케이스가 존재함  
  - 이는 단순히 메모리 latency만이 아니라, 루프 구조에서 실제로 해당 라인을 사용하게 되는 시점이 얼마나 뒤인지, 그리고 prefetch가 앞서나가며 가져오는 라인들이 캐시/TLB에 어떤 부담을 주는지까지 같이 반영된 결과로 보는 편이 자연스러움  

#### (C) stride 32
- best_dist=64로 아주 작은 개선이 있긴 한데(0.55%), 체감상 안정적 결론이라고 말하기는 애매한 수준임  
- 이런 케이스는 약간의 시스템 노이즈, 캐시 상태, 코어 스케줄링 변화로 뒤집힐 가능성이 큼  

#### (D) stride 64, 128, 256
- prefetch가 전반적으로 도움이 안 됨(best_dist none)  
- 이 구간이 특히 흥미로운데, 단조롭게 stride가 커질수록 prefetch가 계속 좋아지는 구조가 아니라는 점이 그대로 드러남  
- 가능 원인 후보
  - 이미 하드웨어 prefetcher가 어느 정도 따라오는 구간이라서 소프트웨어 prefetch가 중복이 되는 경우  
  - 또는 stride가 페이지/캐시 세트 경계를 자주 넘나들면서, prefetch가 가져온 라인이 실제 사용 전에 밀려나거나(캐시 오염), TLB pressure를 더 키우는 경우  
  - 동시에 outstanding miss나 prefetch 요청의 개수가 한계를 만나서 병목이 prefetch 자체가 되는 경우  

#### (E) stride 512, 1024, 2048
- 가장 강하게 개선이 나타난 구간임(약 18%~22%)  
- 큰 stride는 하드웨어 prefetcher가 맞추기 어려운 패턴이 될 가능성이 커지고, 미리 가져온 라인이 실제로 유효하게 쓰일 확률이 올라가면서 소프트웨어 prefetch가 의미를 갖기 쉬움  
- 관측된 best_dist도 16, 18, 24처럼 두 자릿수로 수렴함  
- 이 구간은 test.cpp의 계산 결과와도 비교적 잘 맞는 편임(아래 3절 참고)  

---

## 1-3) stride가 커질수록 base 시간이 단조 증가하지 않는 이유 후보
이번 결과에서 stride가 커지는데도 base_ms가 단조 증가하지 않는 현상은, stride가 커질수록 캐시 미스가 늘어난다는 단순 모델만으로는 설명이 부족한 케이스임. 이번 실험 구조에서는 다음 요인들이 함께 섞일 수 있음  

### 1) offset loop가 만드는 다중 스트림 효과
코드가 `for off in [0..stride-1]` 구조를 가지므로, 관찰 관점에서는 여러 개의 스트림이 interleave되는 형태가 됨  
- stride가 커질수록 서로 다른 `off`가 만드는 stream 개수가 많아지는 쪽으로 보일 수 있음  
- 하드웨어 prefetcher는 스트림 개수, stride 패턴, 히스토리 기반 추정에 영향을 받으므로  
  - 어떤 stride에서는 잘 맞고  
  - 어떤 stride에서는 스트림이 너무 많거나 패턴이 애매해져서 잘 못 맞는  
  구간이 생길 수 있음  
따라서 base는 stride 자체뿐 아니라, prefetcher가 스트림을 얼마나 잘 따라오느냐에도 좌우되는 구조임  

### 2) cache set conflict 가능성
특정 stride(특히 2의 거듭제곱 계열)에서는 접근 주소의 인덱스 비트 패턴 때문에  
- 특정 set에 충돌이 몰리는 상황이 생길 수 있음  
이 경우 stride가 커졌는데도 갑자기 더 나빠지거나, 반대로 어떤 stride에서는 충돌이 덜해져 덜 나빠지는 등 단조성이 깨질 수 있음  

### 3) TLB pressure와 페이지 워크 성격 변화
stride가 커지면 한 번의 접근이 서로 다른 페이지를 더 자주 건드리는 쪽으로 바뀌어  
- DTLB miss 빈도가 달라지고  
- 페이지 워크 비용이 튀는 구간이 생길 수 있음  
특히 워킹셋이 256MB로 큰 조건에서는 TLB 영향이 base 시간에 의미 있게 섞일 수 있음  

### 4) MLP와 outstanding miss 한계
stride 접근은 완전한 pointer-chase처럼 직렬화되지 않고  
- 코어가 여러 미스를 동시에 outstanding으로 걸어 겹쳐 처리할 수 있음(MLP 존재)  
stride에 따라 겹침 정도나 큐 포화 양상이 달라지면, base 시간도 단조 증가 대신 들쭉날쭉해질 수 있음  

---

## 1-4) dist 최적값이 stride별로 달라지고 큰 값도 최적이 되는 이유 후보
dist는 단순 상수가 아니라 `i + dist*stride`로 실제 prefetch 거리(바이트 단위)를 결정하므로, stride가 바뀌면 같은 dist라도 완전히 다른 의미가 됨  

- dist가 너무 작으면 데이터가 늦게 도착해 latency hide가 실패할 수 있음  
- dist가 너무 크면 너무 일찍 가져온 라인이 사용 전에 밀려나거나, 캐시 오염, TLB pressure, 불필요 대역폭 사용이 늘어 손해가 될 수 있음  
- 따라서 최적 dist는 stride마다 달라질 수 있고, 어떤 stride에서는 32, 64 같은 큰 값이 유리해질 수 있음  

큰 dist가 이기는 케이스는 다음 상황과 연결될 수 있음  
- 루프 1회당 비용이 커져 dist를 크게 해야 latency를 가릴 시간이 확보되는 경우  
- 하드웨어 prefetcher와 상호작용하면서 특정 dist에서 충돌이 줄거나, 미스 겹침이 유리해지는 경우  
- 반대로, 후보군이 제한된 실험에서는 큰 dist를 포함하지 않아 none으로 보이는 케이스가 생길 수 있음  

---

## 2) test.cpp 결과 요약
test.cpp는 stride별로 다음 값을 출력함  
- `L_lat_cyc`: pointer-chase 기반으로 추정한 load latency의 대표값(대략 cycles 단위)  
- `T_iter_cyc`: stride 커널의 반복 1회당 비용에 해당하는 대표값(대략 cycles 단위)  
- `dist_pred`: dist를 어느 정도로 잡아야 latency를 가릴 가능성이 있는지 계산한 예측값  
- `best_dist`: dist_pred 주변 후보만 실험해서 나온 best(없으면 none)  

이번에 제공된 test.cpp 출력은 아래와 같았음  

| stride | L_lat_cyc | T_iter_cyc | dist_pred | test best_dist | test improvement |
|---:|---:|---:|---:|---:|---:|
| 1 | 13.511 | 7.068 | 2 | 1 | 6.208% |
| 2 | 13.623 | 7.678 | 2 | 4 | 4.809% |
| 4 | 14.182 | 7.523 | 2 | 3 | 14.049% |
| 8 | 15.438 | 7.587 | 3 | 6 | 6.596% |
| 16 | 24.420 | 7.752 | 4 | 4 | 2.225% |
| 32 | 56.223 | 8.164 | 7 | none | 0.000% |
| 64 | 123.570 | 8.697 | 15 | 22 | 1.350% |
| 128 | 126.804 | 8.789 | 15 | none | 0.000% |
| 256 | 146.153 | 8.644 | 17 | none | 0.000% |
| 512 | 142.379 | 8.462 | 17 | 32 | 10.281% |
| 1024 | 269.052 | 8.258 | 33 | 24 | 2.822% |
| 2048 | 266.339 | 8.035 | 34 | 17 | 8.148% |

### 2-1) dist_pred가 의미하는 것
핵심 아이디어는 다음 형태임  

- 반복 1회당 할 수 있는 다른 작업 시간이 `T_iter`라고 하면  
- dist만큼 ahead로 prefetch를 걸어두면, 실제 사용 시점까지 대략 dist * T_iter 만큼 시간이 생김  
- 이 시간이 메모리 지연 `L_lat`보다 크면, 해당 load는 사용 시점에 이미 캐시에 들어와 있을 가능성이 커짐  

따라서 dist는 대략 `L_lat / T_iter` 정도 이상이면 의미가 생기고, 너무 큰 dist는 캐시 오염과 불필요 prefetch로 손해가 커질 수 있어 최적점이 생기게 됨  

---

## 3) main.cpp의 최적 dist와 test.cpp의 계산 결과 비교
같은 stride라도 main과 test의 best_dist가 항상 같지는 않음  
그럼에도, 이 비교를 통해 다음을 확인할 수 있음  

1) 큰 stride 구간에서는 dist가 두 자릿수로 가는 것이 자연스러운 그림임  
2) 최적 dist는 단조성으로 커지지 않고, stride별로 최적이 달라질 수 있음  
3) dist 최적점은 결국 memory penalty와 반복 1회당 시간의 비율에 의해 결정되는 구조임  

### 3-1) 비교표
- main best_dist는 실제 ms 기준 최적(dist 후보군 전체 스윕 결과)  
- test best_dist는 계산 기반 후보군 주변 실험에서의 best  
- test dist_pred는 계산으로 얻은 예측값  

| stride | main best_dist | test dist_pred | test best_dist | 관측 |
|---:|---:|---:|---:|---|
| 1 | none | 2 | 1 | main에서는 prefetch가 손해인 케이스임 |
| 2 | 15 | 2 | 4 | 작은 stride 구간에서 불일치가 큼 |
| 4 | 64 | 2 | 3 | 작은 stride 구간에서 불일치가 큼 |
| 8 | 15 | 3 | 6 | 오더는 비슷하지만 값은 다름 |
| 16 | 11 | 4 | 4 | 오더는 비슷하지만 값은 다름 |
| 32 | 64 | 7 | none | test 후보군에는 64가 포함되지 않아 none이 될 수 있음 |
| 64 | none | 15 | 22 | main에서는 prefetch가 손해임 |
| 128 | none | 15 | none | 둘 다 효과 없음으로 일치함 |
| 256 | none | 17 | none | 둘 다 효과 없음으로 일치함 |
| 512 | 16 | 17 | 32 | 둘 다 두 자릿수 dist가 의미 있다는 결론으로 수렴함 |
| 1024 | 18 | 33 | 24 | 서로 근접한 범위에서 움직임 |
| 2048 | 24 | 34 | 17 | 서로 근접한 범위에서 움직임 |

### 3-2) 왜 완전히 일치하지 않을 수 있는가
이번 비교에서 특히 stride 2, 4 같은 작은 stride에서 차이가 크게 났는데, 이건 계산이 틀렸다기보다 모델이 단순화된 부분이 원인일 가능성이 큼  

- test.cpp의 `L_lat_cyc`는 pointer-chase로 구한 지연으로, 의도적으로 직렬화된 지연을 재는 성격이 강함  
- main.cpp의 실제 스트라이드 접근은 완전히 직렬화되지 않고, 하드웨어가 어느 정도 메모리 수준 병렬성으로 겹쳐 처리하는 구간이 존재할 수 있음  
- 또한 main.cpp는 dist 후보군을 넓게 두고 ms 단위로 직접 스윕하는데, 작은 개선(몇 퍼센트)은 시스템 노이즈나 캐시 상태에 따라 best_dist가 튈 수 있음  
- dist를 크게 했을 때 좋아지는 케이스는, 단순히 latency를 가리는 효과 외에도
  - 하드웨어 prefetcher와의 상호작용
  - 페이지 경계, TLB 엔트리 사용 패턴
  - prefetch가 만들어내는 캐시 오염 패턴 변화
  같은 요인이 함께 섞이면서 발생할 수 있음  

추가로, test.cpp와 main.cpp의 차이를 한 문장으로 줄이면 다음 형태임  
- test.cpp의 `L_lat_cyc`는 pointer-chase 성격으로 지연을 직렬화해서 재는 값에 가깝고, main.cpp는 MLP와 HW prefetcher 상호작용이 섞인 실제 워크로드에 가까워서 `dist_pred = L_lat / T_iter`는 스케일을 잡는 데는 유용하지만 best_dist를 정확히 맞추기에는 단순화된 모델임  

---

## 4) 결론 정리
- main.cpp 실험 기준으로는, stride가 커졌다고 해서 prefetch가 항상 좋아지는 구조가 아니라는 점이 명확히 관측됨  
- stride 512 이상에서는 소프트웨어 prefetch가 큰 개선을 만들 수 있고, 이때 최적 dist가 대략 16~24 같은 두 자릿수로 나타났음  
- test.cpp에서 계산한 dist_pred는 memory penalty와 반복 1회당 시간을 직접 반영해 dist의 대략적인 크기를 잡는 데 도움이 됨  
- dist 최적점이 존재하는 이유는, dist가 너무 작으면 데이터가 늦게 도착하고, dist가 너무 크면 캐시 오염과 불필요 prefetch 비용이 커지기 때문이며, 이 균형점이 `L_lat`와 `T_iter`의 비율에 의해 대략 결정된다는 해석이 가장 일관적인 설명임  

---

## 5) 다음 개선 아이디어 (result.md 관점에서 짧게)
- main.cpp에서 best_dist가 none이거나 speedup이 1% 미만인 stride들은
  - trial 수를 늘리고 median 외에 IQR 같은 변동성 지표를 같이 기록하면 더 신뢰도 있는 결론이 됨  
- dist 후보군을 stride별로 다르게 주는 방법도 가능함  
  - 예: test.cpp의 dist_pred 주변을 더 촘촘히, 그리고 2의 거듭제곱 근처도 포함하는 방식임  
- prefetch locality 힌트(세 번째 인자)의 변화도 결과를 바꿀 수 있어, 동일 실험을 locality 0~3으로 반복하면 추가 인사이트가 생길 수 있음  
